{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4641ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hqvjet/Projects/kaomoji-intergated-sentiment-analysis/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab96da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'sentiment'],\n",
      "        num_rows: 5548\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'sentiment'],\n",
      "        num_rows: 686\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'sentiment'],\n",
      "        num_rows: 693\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 11426\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1584\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3166\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "vsmec = load_dataset(\"viethq1906/UIT-VSMEC-Sentiment-Relabelled\")\n",
    "vsfc = load_dataset(\"ura-hcmut/UIT-VSFC\")\n",
    "\n",
    "print(vsmec)\n",
    "print(vsfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b2878ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSFC Train unique labels: ['positive' 'negative' 'neutral']\n",
      "VSFC Valid unique labels: ['negative' 'positive' 'neutral' None]\n",
      "VSFC Test unique labels: ['positive' 'negative' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in each split before normalization\n",
    "print(\"VSFC Train unique labels:\", vsfc['train'].to_pandas()['label'].unique())\n",
    "print(\"VSFC Valid unique labels:\", vsfc['validation'].to_pandas()['label'].unique())\n",
    "print(\"VSFC Test unique labels:\", vsfc['test'].to_pandas()['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3af9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - VSMEC: (5548, 2), VSFC: (11426, 2)\n",
      "validation - VSMEC: (686, 2), VSFC: (1583, 2)\n",
      "test - VSMEC: (693, 2), VSFC: (3166, 2)\n",
      "\n",
      "Before mapping:\n",
      "Train unique: ['positive' 'negative' 'neutral']\n",
      "Valid unique: ['negative' 'positive' 'neutral']\n",
      "Test unique: ['positive' 'negative' 'neutral']\n",
      "\n",
      "After mapping:\n",
      "Train unique: [ 1 -1  0] - dtype: int64\n",
      "Valid unique: [-1  1  0] - dtype: int64\n",
      "Test unique: [ 1 -1  0] - dtype: int64\n",
      "\n",
      "NaN counts:\n",
      "Train NaN: 0\n",
      "Valid NaN: 0\n",
      "Test NaN: 0\n",
      "                                            sentence  sentiment\n",
      "0                          slide giáo trình đầy đủ .          1\n",
      "1     nhiệt tình giảng dạy , gần gũi với sinh viên .          1\n",
      "2               đi học đầy đủ full điểm chuyên cần .         -1\n",
      "3  chưa áp dụng công nghệ thông tin và các thiết ...         -1\n",
      "4  thầy giảng bài hay , có nhiều bài tập ví dụ ng...          1\n",
      "train - Merged: (16974, 2)\n",
      "validation - Merged: (2269, 2)\n",
      "test - Merged: (3859, 2)\n",
      "                                            sentence  sentiment\n",
      "0                      khả năng truyền đạt còn kém .         -1\n",
      "1                                  có hứng thú học .          1\n",
      "2       nên phát hành giáo trình chuẩn cho môn học .         -1\n",
      "3                                            quá sàm         -1\n",
      "4  môn học chỉ nên thuyết trình tìm hiểu về egov ...         -1\n",
      "Saved 16974 records to ../res/train.json\n",
      "Saved 2269 records to ../res/validation.json\n",
      "Saved 3859 records to ../res/test.json\n",
      "Saved 16974 records to ../res/train.json\n",
      "Saved 2269 records to ../res/validation.json\n",
      "Saved 3859 records to ../res/test.json\n"
     ]
    }
   ],
   "source": [
    "vsmec_train = vsmec['train'].to_pandas()\n",
    "vsfc_train = vsfc['train'].to_pandas()\n",
    "vsmec_valid = vsmec['validation'].to_pandas()\n",
    "vsfc_valid = vsfc['validation'].to_pandas()\n",
    "vsmec_test = vsmec['test'].to_pandas()\n",
    "vsfc_test = vsfc['test'].to_pandas()\n",
    "\n",
    "# remove NaN\n",
    "for df in [vsfc_train, vsfc_valid, vsfc_test]:\n",
    "    df.dropna(subset=['text', 'label'], inplace=True)\n",
    "\n",
    "# Check shape\n",
    "for split_name, vsmec_split, vsfc_split in [\n",
    "    ('train', vsmec_train, vsfc_train),\n",
    "    ('validation', vsmec_valid, vsfc_valid),\n",
    "    ('test', vsmec_test, vsfc_test),\n",
    "]:\n",
    "    print(f\"{split_name} - VSMEC: {vsmec_split.shape}, VSFC: {vsfc_split.shape}\")\n",
    "\n",
    "# Normalize column names\n",
    "vsfc_train = vsfc_train.rename(columns={'text': 'sentence', 'label': 'sentiment'})\n",
    "vsfc_valid = vsfc_valid.rename(columns={'text': 'sentence', 'label': 'sentiment'})\n",
    "vsfc_test = vsfc_test.rename(columns={'text': 'sentence', 'label': 'sentiment'})\n",
    "\n",
    "# Check unique values before mapping\n",
    "print(\"\\nBefore mapping:\")\n",
    "print(\"Train unique:\", vsfc_train['sentiment'].unique())\n",
    "print(\"Valid unique:\", vsfc_valid['sentiment'].unique())\n",
    "print(\"Test unique:\", vsfc_test['sentiment'].unique())\n",
    "\n",
    "# Normalize sentiment labels\n",
    "vsfc_train['sentiment'] = vsfc_train['sentiment'].map({'negative': -1, 'neutral': 0, 'positive': 1})\n",
    "vsfc_valid['sentiment'] = vsfc_valid['sentiment'].map({'negative': -1, 'neutral': 0, 'positive': 1})\n",
    "vsfc_test['sentiment'] = vsfc_test['sentiment'].map({'negative': -1, 'neutral': 0, 'positive': 1})\n",
    "\n",
    "# Check after mapping\n",
    "print(\"\\nAfter mapping:\")\n",
    "print(\"Train unique:\", vsfc_train['sentiment'].unique(), \"- dtype:\", vsfc_train['sentiment'].dtype)\n",
    "print(\"Valid unique:\", vsfc_valid['sentiment'].unique(), \"- dtype:\", vsfc_valid['sentiment'].dtype)\n",
    "print(\"Test unique:\", vsfc_test['sentiment'].unique(), \"- dtype:\", vsfc_test['sentiment'].dtype)\n",
    "\n",
    "# Check for NaN values\n",
    "print(\"\\nNaN counts:\")\n",
    "print(\"Train NaN:\", vsfc_train['sentiment'].isna().sum())\n",
    "print(\"Valid NaN:\", vsfc_valid['sentiment'].isna().sum())\n",
    "print(\"Test NaN:\", vsfc_test['sentiment'].isna().sum())\n",
    "\n",
    "print(vsfc_train.head())\n",
    "\n",
    "# Concatenate datasets\n",
    "merged_train = pd.concat([vsmec_train, vsfc_train], ignore_index=True)\n",
    "merged_valid = pd.concat([vsmec_valid, vsfc_valid], ignore_index=True)\n",
    "merged_test = pd.concat([vsmec_test, vsfc_test], ignore_index=True)\n",
    "\n",
    "# Shuffle all datasets\n",
    "merged_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "merged_valid = merged_valid.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "merged_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check merged shapes\n",
    "for split_name, merged_split in [\n",
    "    ('train', merged_train),\n",
    "    ('validation', merged_valid),\n",
    "    ('test', merged_test),\n",
    "]:\n",
    "    print(f\"{split_name} - Merged: {merged_split.shape}\")\n",
    "    \n",
    "print(merged_train.head())\n",
    "\n",
    "# Save merged datasets to JSON\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create res directory if it doesn't exist\n",
    "res_dir = '../res'\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "\n",
    "# Function to convert DataFrame to the required JSON format\n",
    "def save_to_json(df, filepath):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        record = {\n",
    "            \"sentence\": row['sentence'],\n",
    "            \"sentiment\": int(row['sentiment'])  # Convert to int to ensure proper format\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Saved {len(records)} records to {filepath}\")\n",
    "\n",
    "# Save each split\n",
    "save_to_json(merged_train, os.path.join(res_dir, 'train.json'))\n",
    "save_to_json(merged_valid, os.path.join(res_dir, 'validation.json'))\n",
    "save_to_json(merged_test, os.path.join(res_dir, 'test.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651911e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
